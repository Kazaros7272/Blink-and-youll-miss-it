<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>Blink → Red demo</title>
  <style>
    :root {
      --bg-normal: #111;
      --bg-blink: #c50000;
    }
    html, body {
      margin: 0;
      height: 100%;
      background: var(--bg-normal);
      color: #fff;
      font-family: system-ui, Segoe UI, Roboto, Helvetica, Arial, sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
    }
    #video {
      width: 90vmin;
      max-width: 480px;
      border-radius: 8px;
      display: block;
    }
    #canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 0;
      height: 0;
    }
    #status, #fps, #warning {
      margin-top: 1rem;
      font-size: 1.1rem;
      opacity: .7;
    }
    /* Adjust spacing between elements */
    #fps {
      margin-top: 0.5rem;
    }
    #warning {
      color: #ff0;
      font-weight: bold;
    }
  </style>
</head>
<body>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>
  <div id="status">Waiting for camera…</div>
  <div id="fps">FPS: 0</div>
  <div id="warning"></div>
  
  <!-- MediaPipe bundles -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script>
    (async () => {
      const video   = document.getElementById('video');
      const canvas  = document.getElementById('canvas');
      const status  = document.getElementById('status');
      const fpsDisplay = document.getElementById('fps');
      const warningDisplay = document.getElementById('warning');
      const ctx     = canvas.getContext('2d');
      
      /* ---- blink-detection parameters ---- */
      const EAR_THRESHOLD = 0.27; // increased from 0.25 to try
      let dynamicClosedFrames = 1;
      let closedCtr = 0;
  
      const leftIdx  = [362, 385, 387, 263, 373, 380]; // MediaPipe indices
      const rightIdx = [33, 160, 158, 133, 153, 144];
      
      const dist = (a, b) => Math.hypot(a.x - b.x, a.y - b.y);
      // Compute eye aspect ratio
      const ear = (lm, indices) =>
        (dist(lm[indices[1]], lm[indices[5]]) + dist(lm[indices[2]], lm[indices[4]])) /
        (2 * dist(lm[indices[0]], lm[indices[3]]));
  
      function flash() {
        document.body.style.background = 'var(--bg-blink)';
        setTimeout(
          () => document.body.style.background = 'var(--bg-normal)', 
          300
        );
      }
  
      /* ---- FaceMesh setup ---- */
      const faceMesh = new FaceMesh({
        locateFile: f => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${f}`
      });
      faceMesh.setOptions({
        maxNumFaces: 1,
        refineLandmarks: true,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
      });
  
      faceMesh.onResults(results => {
        if (!results.multiFaceLandmarks.length) {
          status.textContent = 'No face detected';
          closedCtr = 0;
          return;
        }
        status.textContent = 'Tracking… Blink away!';
  
        const lm = results.multiFaceLandmarks[0];
        const earAvg = (ear(lm, leftIdx) + ear(lm, rightIdx)) / 2;
  
        // Check for blink by accumulating closed frames
        if (earAvg < EAR_THRESHOLD) {
          closedCtr++;
        } else {
          if (closedCtr >= dynamicClosedFrames) flash();
          closedCtr = 0;
        }
  
        /* Optional drawing */
        canvas.width  = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);
        ctx.fillStyle = '#0f0';
        lm.forEach(p =>
          ctx.fillRect(p.x * canvas.width - 1, p.y * canvas.height - 1, 3, 3)
        );
      });
  
      /* ---- FPS Calculation ---- */
      let lastFrameTime = performance.now();
      let currentFps = 30;
  
      /* ---- Camera helper ---- */
      const cam = new Camera(video, {
        onFrame: async () => {
          const now = performance.now();
          const delta = now - lastFrameTime;
          currentFps = 1000 / delta;
          lastFrameTime = now;
  
          // Update the FPS display
          fpsDisplay.textContent = `FPS: ${currentFps.toFixed(1)}`;
          dynamicClosedFrames = Math.max(1, Math.floor(currentFps * 0.1));
          if (currentFps < 8) {
            warningDisplay.textContent = "Warning: Low FPS (<8) – detections may be inaccurate.";
          } else {
            warningDisplay.textContent = "";
          }
  
          await faceMesh.send({ image: video });
        },
        width: 480,
        height: 360
      });
      
      cam.start()
         .then(() => status.textContent = 'Camera on -- position your face in view')
         .catch(e => status.textContent = 'Camera error: ' + e.message);
  
    })();
  </script>
</body>
</html>
